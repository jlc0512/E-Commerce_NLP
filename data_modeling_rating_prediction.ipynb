{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5397776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5085694a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jillian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jillian/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jillian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jillian/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#Required text pre-processing libraries are imported\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# download the stopwords and wordnet corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "# import tokenize from nltk library\n",
    "from nltk import tokenize\n",
    "# import WordNetLemmatizer from nltk library\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "#Required data visualisation libraries are imported\n",
    "import plotly.express as px\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Required prediction modelling libraries are imported\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, precision_recall_curve, auc, roc_curve, accuracy_score, recall_score, classification_report, f1_score, precision_score, precision_recall_fscore_support, roc_auc_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31bf0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in single_word dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2458e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/single_word_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/single_word_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py:686\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    633\u001b[0m     engine_specified \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    635\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    636\u001b[0m     delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[1;32m    637\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    683\u001b[0m     skip_blank_lines\u001b[38;5;241m=\u001b[39mskip_blank_lines,\n\u001b[1;32m    684\u001b[0m )\n\u001b[0;32m--> 686\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py:452\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    449\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp_or_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py:946\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 946\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py:1178\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_engine\u001b[39m(\u001b[38;5;28mself\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1178\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[43mCParserWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/io/parsers.py:2008\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols_dtype \u001b[38;5;241m=\u001b[39m _validate_usecols_arg(kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   2006\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[0;32m-> 2008\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2009\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m   2011\u001b[0m passed_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:382\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:674\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/single_word_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/single_word_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f8c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.String.isna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723cd59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#due to adding words to our stop list, we now have 4 \"Clean\" reviews with no words; \n",
    "#we will eliminate these rows for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d49a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.String.isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e9f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c062f",
   "metadata": {},
   "source": [
    "# Modeling with Single Words Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c84d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#will be using accuracy as metric; want to identify neutral/negative sentiments and be able\n",
    "#to sample enough of them to get a clear view of if there is a consistent issue\n",
    "#that we as a company can change for our soft roll out\n",
    "#also want to be able to ball park which items will be most popular, so we can have\n",
    "#an appropriate amount of inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376e4559",
   "metadata": {},
   "source": [
    "For each model we created a pipeline that includes a TF-IDF vectorizer, a smote component to deal with class imbalance, and the classifier itself. We elected to use a TF-IDF vectorizer instead of a count vectorizer because it provides a way to understand the importance of each word to the tweet, as well as just how frequently it occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c899a02",
   "metadata": {},
   "source": [
    "To give the model a little bit more information with those same features, we'll use a TfidfVectorizer (documentation here) so that it counts not only the term frequency (tf) within a single document, it also includes the inverse document frequency (idf) — how rare the term is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19a9508",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32529eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify X as the cleaned strings in df and y as the target-Rating.\n",
    "X = df['String']\n",
    "y = df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performed the train-test split, using 20% for the hold-out data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe95342",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f302adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a vectorizer \n",
    "# Instantiate and fit/transform X_train using the TF-IDF vectorizer.\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_vectorized = tfidf.fit_transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3afd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert vectorized X_train to a vector for easier visual inspection.\n",
    "X_train_vec = pd.DataFrame.sparse.from_spmatrix(X_train_vectorized, columns=tfidf.get_feature_names())\n",
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c543b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data using TF-IDF Vectorizer trained on X_train, y_train\n",
    "X_test_vectorized = tfidf.transform(X_test)\n",
    "X_test_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0949d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for visual inspection\n",
    "X_test_vec = pd.DataFrame.sparse.from_spmatrix(X_test_vectorized, columns=tfidf.get_feature_names())\n",
    "X_test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed992e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to return scores in cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5152b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy = make_scorer(accuracy_score)\n",
    "\n",
    "#f1\n",
    "custom_f1 = make_scorer(\n",
    "    f1_score, \n",
    "    average=\"weighted\")\n",
    "\n",
    "# Precision\n",
    "multi_prec = make_scorer(\n",
    "    precision_score,\n",
    "    average=\"weighted\")\n",
    "\n",
    "# Recall\n",
    "multi_rec = make_scorer(\n",
    "    recall_score,\n",
    "    average=\"weighted\")\n",
    "\n",
    "# This function will allow for quick cross-validation of the chosen score for each of our models.\n",
    "def cross_val(model, X, y, custom_scorer, kfolds=5):\n",
    "    \"\"\" Perform cross-validated scoring and store/print results \"\"\"\n",
    "    results = cross_val_score(model, X, y, cv=kfolds, scoring=custom_scorer)\n",
    "    mean = np.mean(results)\n",
    "    median = np.median(results)\n",
    "    std = np.std(results)\n",
    "    if custom_scorer == accuracy:\n",
    "        print(f\"Mean accuracy score: \", {mean}, \".\")\n",
    "        print(f\"Median acuracy score: \", {median}, \".\")\n",
    "        print(f\"Standard Deviation in accuracy: \", {std}, \".\") \n",
    "    elif custom_scorer == custom_f1:\n",
    "        print(f\"Mean f1 score: \", {mean}, \".\")\n",
    "        print(f\"Median f1 score: \", {median}, \".\")\n",
    "        print(f\"Standard Deviation in f1 score: \", {std}, \".\") \n",
    "    elif custom_scorer == multi_prec:\n",
    "        print(f\"Mean precision score: \", {mean}, \".\")\n",
    "        print(f\"Median precision score: \", {median}, \".\")\n",
    "        print(f\"Standard Deviation in precision score: \", {std}, \".\") \n",
    "    elif custom_scorer == multi_rec:\n",
    "        print(f\"Mean recall score: \", {mean}, \".\")\n",
    "        print(f\"Median recall score: \", {median}, \".\")\n",
    "        print(f\"Standard Deviation in recall score: \", {std}, \".\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b315fe5",
   "metadata": {},
   "source": [
    "## Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c897e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Dummy Classifier \n",
    "dummy_model = DummyClassifier()\n",
    "\n",
    "#Fit and Evaluate Dummy Classifier\n",
    "dummy_model.fit(X_train_vectorized, y_train)\n",
    "dummy_yhat = dummy_model.predict(X_train)\n",
    "plot_confusion_matrix(dummy_model, X_train, y_train);\n",
    "print(accuracy_score(y_train, dummy_yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278803da",
   "metadata": {},
   "source": [
    "We see our Dummy Model predicts our majority label, 1, for each observation. Due to class imbalance, the model performed at 55% accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b632949",
   "metadata": {},
   "source": [
    "## Initial Model CV Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc488cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [MultinomialNB(), LogisticRegression(), KNeighborsClassifier(), DecisionTreeClassifier(), XGBClassifier(), RandomForestClassifier()]:\n",
    "    # Perform cross validation\n",
    "    results = cross_val_score(algorithm, X_train_vectorized, y_train)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6bc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Logistic Regression cannot be used for multi-class classification; should explore XGBClassifier and RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c6506",
   "metadata": {},
   "source": [
    "# Setting up SMOTE Subpipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "subpipe_smote = SMOTE(sampling_strategy='auto', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19067dd9",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94eb181",
   "metadata": {},
   "source": [
    "### Initial Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ab1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our random forest pipeline to incorporate column transformer, use default hyperparameters\n",
    "rfc_pipe = Pipeline(steps=[('vect', TfidfVectorizer(max_features=2000)),\n",
    "                           ('rfc', RandomForestClassifier(random_state=42))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c32459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our random forest classifier to the training data\n",
    "rfc_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbb77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate initial accuracy score of random forest with default hyperparameters\n",
    "rfc_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b52cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not surprising our model has a score of 1; going to be overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c327345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained cross-validated accuracy score\n",
    "cross_val(rfc_pipe, X_train, y_train, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d720c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oof... much worse score when cross validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753bc2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate XGBClassifier with SMOTE subpipe\n",
    "rfc_sm_pipe = Pipeline(steps=[('vect', TfidfVectorizer(max_features=2000)), \n",
    "                           ('sm', subpipe_smote),\n",
    "                            ('rfc', RandomForestClassifier(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_sm_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a47e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_sm_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained cross-validated accuracy score\n",
    "cross_val(rfc_sm_pipe, X_train, y_train, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facb3d95",
   "metadata": {},
   "source": [
    "## Initial Random Forest Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3faac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our grid for the grid search parameters\n",
    "params = {'rfc__n_estimators': [50, 100, 150],\n",
    "          'rfc__min_samples_split': [2, 10, 50],\n",
    "          'rfc__max_depth': [5, 10, 15],\n",
    "          'vect__max_features': [2000, 3000],\n",
    "          'vect__ngram_range': [(1,1), (2,2)]}\n",
    "\n",
    "# set up GridSearchCV object\n",
    "grid_rfc = GridSearchCV(rfc_pipe, param_grid=params, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25029ea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grid_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d834d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best hyper parameters from our first grid search\n",
    "#grid_rfc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ba0b9",
   "metadata": {},
   "source": [
    "- 'rfc__max_depth': 15,\n",
    "- 'rfc__min_samples_split': 2,\n",
    "- 'rfc__n_estimators': 150,\n",
    "- 'vect__max_features': 2000,\n",
    "- 'vect__ngram_range': (1, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c6995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maxed out parameters for max_depth and n_estimators; will increae for next grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e4dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the best accuracy score from our first grid search\n",
    "#grid_rfc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf798f0d",
   "metadata": {},
   "source": [
    "0.5529048523773297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687db028",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_rfc.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf067f8",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our default XGB pipeline\n",
    "XGB_pipe = ImPipeline(steps=[('vect', TfidfVectorizer(max_features=2000)), \n",
    "                             ('XGB', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662fa959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the xgb pipeline to our training data\n",
    "XGB_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c8d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assess the score\n",
    "XGB_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c71ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained cross-validated accuracy score\n",
    "cross_val(XGB_pipe, X_train, y_train, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b3a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_preds = XGB_pipe.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b83dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, training_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4237b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(XGB_pipe, X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658c6223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate XGBClassifier with SMOTE subpipe\n",
    "XGB_sm_pipe = ImPipeline(steps=[('vect', TfidfVectorizer(max_features=2000)), \n",
    "                           ('sm', subpipe_smote),\n",
    "                            ('XGB', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715519ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_sm_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebdc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assess the score\n",
    "XGB_sm_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa28f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained cross-validated accuracy score\n",
    "cross_val(XGB_sm_pipe, X_train, y_train, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7068819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(XGB_sm_pipe, X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results not as good with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d980c",
   "metadata": {},
   "source": [
    "## Initial XGBoost Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c63e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our massive grid for the grid search parameters\n",
    "paramsXGB = {\n",
    "    'XGB__learning_rate': [0.1, 0.2],\n",
    "    'XGB__max_depth': range(3, 10, 2),\n",
    "    'XGB__min_child_weight': range(1, 8, 2),\n",
    "    'XGB__gamma': [0, .1, .2],\n",
    "    'XGB__subsample': [.5, .75, 1],\n",
    "    'vect__ngram_range': [(1,1), (2,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746770ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_XGB = GridSearchCV(XGB_pipe, param_grid=paramsXGB, cv=5, verbose=3, n_jobs=-2)\n",
    "\n",
    "#Fit grid search object to our training data to check the hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_XGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5832d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best hyper parameters from our first grid search\n",
    "#grid_XGB.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fe2cc1",
   "metadata": {},
   "source": [
    "- {'XGB__gamma': 0.1,\n",
    "- 'XGB__learning_rate': 0.2,\n",
    "- 'XGB__max_depth': 9,\n",
    "- 'XGB__min_child_weight': 7,\n",
    "- 'XGB__subsample': 0.75,\n",
    "- 'vect__ngram_range': (1, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the best accuracy score from our first grid search\n",
    "#grid_XGB.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b5136",
   "metadata": {},
   "source": [
    "0.6189529572493482"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c091b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_XGB, X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, grid_XGB.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a0df0",
   "metadata": {},
   "source": [
    "If our review is a 5, we are most likely rating that review a 5 (high recall). However, we are also rating many addition reviews a 5 (low precision). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44304f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our XGB pipeline with best params\n",
    "XGB_pipe2 = ImPipeline(steps=[('vect', TfidfVectorizer(max_features=2000)), \n",
    "                             ('XGB', XGBClassifier(gamma=.1, learning_rate=.2, max_depth=9, min_child_weight=7, subsample=.75))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190003bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a181fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_pipe2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa6ab1",
   "metadata": {},
   "source": [
    "We have achieved 79% accuracy with our params from our grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val(XGB_pipe2, X_train, y_train, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167b5ff2",
   "metadata": {},
   "source": [
    "As expected, when cross-validating our mean accuracy is only 61.9% (same as .best_score_)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe9e5e2",
   "metadata": {},
   "source": [
    "Since we maxed out learning rate, max depth, and min child weight, I will adjust these and use higher ranges in my next grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a48037",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsXGB = {\n",
    "    'XGB__learning_rate': [0.1, 0.2, 0.3],\n",
    "    'XGB__max_depth': [9, 12, 15],\n",
    "    'XGB__min_child_weight': [6, 8, 10],\n",
    "    'XGB__gamma': [0, .1, .2],\n",
    "    'XGB__subsample': [.5, .75, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82552c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_XGB2 = GridSearchCV(XGB_pipe, param_grid=paramsXGB, cv=5, verbose=3, n_jobs=-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a81ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_XGB2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3345b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_XGB2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebe39f8",
   "metadata": {},
   "source": [
    "- {'XGB__gamma': 0.2,\n",
    "- 'XGB__learning_rate': 0.2,\n",
    "- 'XGB__max_depth': 12,\n",
    "- 'XGB__min_child_weight': 10,\n",
    "- 'XGB__subsample': 0.75}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d782b93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_XGB2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa35da3",
   "metadata": {},
   "source": [
    "0.6188977238883981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df94c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_XGB2, X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0a20cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this grid search performed worse than last grid search; will try adding\n",
    "#Smote in pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db767ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as XGB_pipe2 but with Smote\n",
    "XGB_pipe3 = ImPipeline(steps=[('vect', TfidfVectorizer(max_features=2000)), \n",
    "                              ('sm', subpipe_smote),\n",
    "                             ('XGB', XGBClassifier(gamma=.1, learning_rate=.2, max_depth=9, min_child_weight=7, subsample=.75))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_pipe3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_pipe3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02254bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained cross-validated accuracy score\n",
    "cross_val(XGB_pipe3, X_train, y_train, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c02ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross val mean of 59.9%, median of 59.8%; not as good as results without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb4a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, XGB_pipe3.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb838a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(XGB_pipe3, X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4905dcb",
   "metadata": {},
   "source": [
    "# Modeling with Bigrams Without Additional Stop Words Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38a478",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('./data/bigram_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d163f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa36a72",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe9454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split for data to utilize bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befa5c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify X as the cleaned strings in df and y as the target-Rating.\n",
    "X2 = df2['String']\n",
    "y2 = df2['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc14f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performed the train-test split, using 20% for the hold-out data.\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,\n",
    "                                                    y2,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24972561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a vectorizer \n",
    "# Instantiate and fit/transform X_train using the TF-IDF vectorizer.\n",
    "tfidf = TfidfVectorizer(ngram_range=(2,2), max_features=2000)\n",
    "X_train2_vectorized = tfidf.fit_transform(X_train2)\n",
    "X_train2_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aaa1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert vectorized X_train to a vector for easier visual inspection.\n",
    "X_train2_vec = pd.DataFrame.sparse.from_spmatrix(X_train2_vectorized, columns=tfidf.get_feature_names())\n",
    "X_train2_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb45b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data using TF-IDF Vectorizer trained on X_train, y_train\n",
    "X_test2_vectorized = tfidf.transform(X_test2)\n",
    "X_test2_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf83c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for visual inspection\n",
    "X_test2_vec = pd.DataFrame.sparse.from_spmatrix(X_test2_vectorized, columns=tfidf.get_feature_names())\n",
    "X_test2_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28ecfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [MultinomialNB(), KNeighborsClassifier(), DecisionTreeClassifier(), XGBClassifier(), RandomForestClassifier()]:\n",
    "    # Perform cross validation\n",
    "    results = cross_val_score(algorithm, X_train2_vectorized, y_train2)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f103d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##MultinomialNB best in initial cv with defaults; initially not peforming as well with bigrams, will try tweaking models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222fec4",
   "metadata": {},
   "source": [
    "## Multinomial Model with Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our default MultinomialNB pipeline\n",
    "mnb_pipe = ImPipeline(steps=[('vect', TfidfVectorizer(ngram_range=(2,2), max_features=2000)), \n",
    "                             ('mnb', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ac3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_pipe.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06390266",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_pipe.score(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained cross-validated accuracy score\n",
    "cross_val(mnb_pipe, X_train2, y_train2, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08410b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_XGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7068117",
   "metadata": {},
   "source": [
    "## Random Forest Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the same initial grid search on this data set that did not eliminiate additional stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa4fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our grid for the grid search parameters\n",
    "params = {'rfc__n_estimators': [50, 100, 150],\n",
    "          'rfc__min_samples_split': [2, 10, 50],\n",
    "          'rfc__max_depth': [5, 10, 15],\n",
    "          'vect__max_features': [2000, 3000],\n",
    "          'vect__ngram_range': [(1,1), (2,2)]}\n",
    "\n",
    "# set up GridSearchCV object\n",
    "grid_rfc = GridSearchCV(rfc_pipe, param_grid=params, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db967e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grid_rfc.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best hyper parameters from our first grid search\n",
    "#grid_rfc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2488c270",
   "metadata": {},
   "source": [
    "- {'rfc__max_depth': 15,\n",
    "- 'rfc__min_samples_split': 2,\n",
    "- 'rfc__n_estimators': 50,\n",
    "- 'vect__max_features': 2000,\n",
    "- 'vect__ngram_range': (1, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b96d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the best accuracy score from our first grid search\n",
    "#grid_rfc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af531b23",
   "metadata": {},
   "source": [
    "0.5550463303274542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599519d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##still seeing ngram_range of (1,1) (single words) producing better results; better results \n",
    "#using no additional stop words cleaned... interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c360e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our grid for the grid search parameters\n",
    "params = {'rfc__n_estimators': [25, 50, 75],\n",
    "          'rfc__min_samples_split': [2, 3, 5],\n",
    "          'rfc__max_depth': [15, 20, 25],\n",
    "          'vect__ngram_range': [(1,1), (2,2)]}\n",
    "\n",
    "# set up GridSearchCV object\n",
    "grid_rfc2 = GridSearchCV(rfc_pipe, param_grid=params, cv=5, verbose=3, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32f5de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e918ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4796bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our massive grid for the grid search parameters\n",
    "params5 = {'rfc__n_estimators': [15, 20, 25],\n",
    "           'rfc__max_depth': [20, 25, 30],\n",
    "           'rfc__max_features': ['sqrt', 0.1, 0.2, 0.5],\n",
    "           'rfc__min_samples_split': [2, 3, 4],\n",
    "           'rfc__min_impurity_decrease': [0, 0.05, 0.1]}\n",
    "\n",
    "# set up GridSearchCV object\n",
    "grid_rfc3 = GridSearchCV(rfc_pipe, param_grid=params5, cv=5, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ed5cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642bb129",
   "metadata": {},
   "source": [
    "0.5900157236660618"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f143c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rfc3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f97ea3",
   "metadata": {},
   "source": [
    "-{'rfc__max_depth': 30,\n",
    "- 'rfc__max_features': 0.1,\n",
    "- 'rfc__min_impurity_decrease': 0,\n",
    "- 'rfc__min_samples_split': 3,\n",
    "- 'rfc__n_estimators': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f773933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
